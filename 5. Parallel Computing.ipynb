{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing in Julia\n",
    "\n",
    "Julia is designed from the ground up to be parallel. Let's start understanding the parallel computing model in Julia. \n",
    "\n",
    "- Julia's implementation of message passing is different from other environments such as MPI. \n",
    "- Communication in Julia is generally \"one-sided\", meaning that the programmer needs to explicitly manage only one process in a two-process operation. \n",
    "- Furthermore, these operations typically do not look like \"message send\" and \"message receive\" but rather resemble higher-level operations like calls to user functions.\n",
    "\n",
    "But before we start exploring these constructs, let us look at what a Julia `Task` is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "A good first reference for most things in Julia is by referencing the documentation. You can do this by typing `?` followed by the keyword you'd like to refer. \n",
    "\n",
    "Since our first discussion is on Tasks, let us load the documentation for a `Task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Julia Task is: \n",
    "\n",
    "- a very lightweight coroutine\n",
    "- Not a thread!\n",
    "- Internal to and scheduled by a Julia Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function mytask()\n",
    "    println(\"Going to take a nap.\")\n",
    "    sleep(10)\n",
    "    println(\"Woke up.\")\n",
    "    rand()\n",
    "end\n",
    "\n",
    "t=Task(mytask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened here? We've created a task just like how the documentation told us. But is it running? \n",
    "\n",
    "The task is currently a `runnable`, which means that it is _created_ but not _scheduled_ yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling and waiting on a task\n",
    "\n",
    "`schedule` starts the task, but will *return immediately*. This means that it does **not** block the master process.\n",
    "\n",
    "(**NOTE**: Run the next two cells immediately one after the other before looking at the accompanying text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schedule(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting on a task\n",
    "\n",
    "The task has now been scheduled and is actively running in the background. Since it hasn't blocked the master process, we can perform some computation in the meantime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "println(\"Doing something else while t is taking a nap...\")\n",
    "inv(rand(100, 100))\n",
    "@time @show wait(t)\n",
    "@show t.state\n",
    "println(\"task finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@async` - syntax sugar for creating and scheduling tasks\n",
    "\n",
    "Of course, we can **create and schedule tasks in one go** by putting code in an `@async` block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=@async begin\n",
    "    println(\"Going to take a nap.\")\n",
    "    sleep(5)\n",
    "    println(\"Woke up.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, before the 5 seconds of sleep time are up, we can schedule computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "21+21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels\n",
    "\n",
    "Channels are used for communication between Tasks. To demonstrate, consider the following simple producer-consumer model, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Channel{Int}(1)\n",
    "result = Channel{Int}(1)\n",
    "doubler = @async while true\n",
    "    x = take!(input)\n",
    "    println(\"Got message $x\")\n",
    "    put!(result, 2x)\n",
    "end\n",
    "\n",
    "printer = @async while true\n",
    "    res = take!(result)\n",
    "    @show res\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some input to the `Channel` via the `put!` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Interact\n",
    "@manipulate for i=1:100\n",
    "    put!(input, i)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Julia Processes, running \"Remote Tasks\"\n",
    "\n",
    "Now let's start running tasks remotely, on other Julia processes. First, we need to request our cluster manager (`JuliaRun`) for 8 worker Julia processes. Note that this means that the **master** process can now **shedule work** on the 4 worker processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JuliaRunClient\n",
    "ctx = Context()\n",
    "nb = self()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initParallel()\n",
    "@result setJobScale(ctx, nb, 8)\n",
    "waitForWorkers(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were on your own laptop or on a cluster that isn't set up with `JuliaRun`, you should use the `addprocs` command to initialize Julia worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run if using the notebook on your own computer\n",
    "# addprocs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a master process and 4 worker processes, the total number of processes we have initialized is 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "procs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider a simple example to demonstrate the use of these new tools. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate $\\pi$ in parallel\n",
    "\n",
    "There's a simple monte carlo method one can use to calculate $\\pi$: \n",
    "1. Remember that the ratio of the area of a unit circle and a unit square is: \n",
    "$$ 4r^2 / \\pi r^2 = \\pi / 4$$ where $r$ is the radius of the circle.\n",
    "2. Next, remember that the square of the coordinates of a point gives you the distance from the origin. \n",
    "3. We can now randomly simulate `N` points, and calculate the fraction of points that fall within the unit circle. \n",
    "4. This is the ratio of the area of a unit circle and unit square. 4 times this ratio gives you the value of $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function trials(numsteps=1000)  # default value of the parameter\n",
    "    pos = 0 \n",
    "    for j in 1:numsteps\n",
    "        pos += Int(rand()^2 + rand()^2 < 1)\n",
    "    end\n",
    "    return pos\n",
    "end\n",
    "\n",
    "function estimate_pi(in_circle, N)\n",
    "    4in_circle / N\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works with 10^8 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimate_pi(trials(10^8), 10^8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@spawnat` - schedule tasks on different procceses \n",
    "\n",
    "`@spawnat` is like @async but runs on a different process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "f=@spawnat 3 begin\n",
    "    println(\"Process \", myid(), \" starting random trials\")\n",
    "    res = trials(10^8)\n",
    "    println(\"Process \", myid(), \" done\")\n",
    "    res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the curious `Future(3,1,12,Nullable{Any}())` thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Future` is a reference to the computation on a Julia worker (aka remote) process. Doing `f[]` returns its values\n",
    "\n",
    "Now our monte carlo simulation to estimate $\\pi$ is embarrassingly parallel, so we can offload some of the computation to another Julia process. Just like we created a task using `@async`, but this time it's running a task on a remote process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function remote_trials(pid,n)\n",
    "    @spawnat pid begin\n",
    "        println(\"Process \", myid(), \" starting trials\")\n",
    "        trials(n)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let us schedule 1000 trials on process 2. Since this task is scheduled on another process, it returns a `Future`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remote_trials(2, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, to estimate $\\pi$ parallel, we need to spawn trials on all our worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function parallel_trials(n, pids=workers())\n",
    "    @time futures = [remote_trials(p,n) for p in pids]\n",
    "    sum([f[] for f in futures])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of them would start a number of trials and return the number of trials that fell within the unit circle. Eventually, we divide by the total number of trials, and estimate the value of $\\pi$. Let us see if our simulation works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time estimate_pi(parallel_trials(10^8), 10^8*nworkers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Remember to run it twice to get the true time!)\n",
    "\n",
    "Let us compare with time in serial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time estimate_pi(trials(10^8*nworkers()), 10^8*nworkers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Arrays\n",
    "\n",
    "We've played with the basic elements of Julia's parallel computing infrastructure. This is a one-sided communication model, and using some of these basic constructs requires understanding the model.\n",
    "\n",
    "But what if, as a user, you don't really want to think about your parallel model? What if you can abstract out this logic and just use a simple array interface to perform distributed computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you were running this on your local notebook, you would do this to add processes\n",
    "# addprocs(8)\n",
    "# Use package for distributed arrays\n",
    "using DistributedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply a map to the vector\n",
    "map(t -> t*t, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this `Array` into a `DArray` (a distributed array), use `distribute`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the vector distributed\n",
    "D = distribute(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `distribute` command cuts the `Array` into chunks and then stores them on the different processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show how the vector is distributed accross the workers\n",
    "D.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you run a `map` on a `DArray`, it runs in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply map to distributed vector (looks identical to non-distributed case)\n",
    "map(t -> t*t, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about this is `DArray`s aren't restricted to numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map(t -> Dates.monthname((t - 1) % 12 + 1), D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can parse and understand this next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthString = map(t -> Dates.monthname((t - 1) % 12 + 1) |> s -> s*\" is my favorite month.\\n\", D) |>\n",
    "    t -> reduce(*, Array(t))\n",
    "println(monthString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also declare a distrubted array of matrices via a distributed comprehension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D55 = @DArray [randn(5,5) for i = 1:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And subsequently `map` a function on them in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute singular values of the dsitributed vector of matrices\n",
    "Dsvd = map(svdvals, D55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random walks\n",
    "\n",
    "Now, we will look at one of the simplest types of Monte Carlo numerical simulation, random walks.\n",
    "\n",
    "In the simplest random walk, a particle starts at $0$ and jumps to the left ($-1$) or the right ($+1$) with equal probability.\n",
    "\n",
    "The following is a simple implementation of a single random walk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time begin\n",
    "    \n",
    "    numsteps = 1000\n",
    "    pos = 0 \n",
    "    for j in 1:numsteps\n",
    "\n",
    "        if rand() < 0.5\n",
    "            step = -1\n",
    "        else\n",
    "            step = +1\n",
    "        end\n",
    "\n",
    "        pos += step \n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap it in a function, which is good programming practice, and allows us to have `numsteps` as a paramater.\n",
    "It turns out to have an additional, important effect in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Single 1D random walk from the origin.\n",
    "Returns the final position after `numsteps` steps.\"\"\"\n",
    "function walk(numsteps=1000)  # default value of the parameter\n",
    "    \n",
    "    pos = 0 \n",
    "    \n",
    "    for j in 1:numsteps\n",
    "\n",
    "        if rand() < 0.5   # can replace by rand(Bool)\n",
    "            step = -1\n",
    "        else\n",
    "            step = +1\n",
    "        end\n",
    "\n",
    "        pos += step \n",
    "    end\n",
    "    \n",
    "    return pos\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time walk(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time walk(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@time walk(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to understand what each walker is doing is by visualizing its path. In Julia, most visualization is done via the `Plots` package, which an umbrella package with a uniform API across different plotting libraries (aka *backends*). Let's load the `plotly` backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots; plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us record the position at each step via a new function `trajectory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function trajectory(numsteps=1000)\n",
    "\n",
    "    pos = 0 \n",
    "    positions = [pos]\n",
    "\n",
    "    for j in 1:numsteps\n",
    "\n",
    "        if rand() < 0.5\n",
    "            step = -1\n",
    "        else\n",
    "            step = +1\n",
    "        end\n",
    "\n",
    "        pos += step \n",
    "        push!(positions, pos)\n",
    "\n",
    "    end\n",
    "    \n",
    "    positions\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numsteps = 1000\n",
    "plot(1:numsteps, trajectory(numsteps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us get a sense of how much time this takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@manipulate for k in 3:9\n",
    "    @elapsed walk(10^k)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(3:9, [@elapsed walk(10^k) for k = 3:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add parallelism\n",
    "\n",
    "Now that we have a sense of how much time it takes, we now offload work to other Julia processes. Let's now use `DArrays` to parallelize this random walk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's our `walk` function again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere function walk(numsteps)\n",
    "    pos = 0\n",
    "\n",
    "    for j in 1:numsteps\n",
    "        \n",
    "        if rand(Bool)  # NB\n",
    "            step = -1\n",
    "        else\n",
    "            step = +1\n",
    "        end\n",
    "        \n",
    "        pos += step # ifelse(rand() < 0.5, -1, +1)\n",
    "    end\n",
    "    \n",
    "    return pos\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define how many walkers we want and how many steps we want them to walk. In serial, all our walkers are present on a single process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    numsteps   = 10000\n",
    "    numwalkers = 100000 \n",
    "end\n",
    "serialwalkers = collect(1:numwalkers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with `distribute`, the walkers are distributed across all worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallelwalkers = distribute(serialwalkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as earlier, we can examine the distribution by looking at the indices stored on each worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallelwalkers.indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeof(parallelwalkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "Most benchmarking in Julia is done via the package `BenchmarkTools`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Compat\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us perform the random walks by calling the `map` function on all the workers. \n",
    "\n",
    "In serial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@benchmark map(_ -> walk(numsteps), serialwalkers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@benchmark positions = map( _ -> walk(numsteps), parallelwalkers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
